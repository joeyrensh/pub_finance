import os
import pandas as pd
import glob
import tempfile
from datetime import datetime


def clean_stock_data_pandas_batch(
    stock_files, delete_before_date="2024-01-01", chunk_size=10000
):
    """
    ä½¿ç”¨pandasåˆ†æ‰¹å¤„ç†å¤§æ–‡ä»¶çš„æ•°æ®æ¸…ç†ç¨‹åº

    å‚æ•°:
    delete_before_date: åˆ é™¤æ—©äºæ­¤æ—¥æœŸçš„æ•°æ®ï¼Œæ ¼å¼ä¸º'YYYY-MM-DD'
    chunk_size: æ¯æ¬¡å¤„ç†çš„æ•°æ®å—å¤§å°ï¼Œé»˜è®¤10000è¡Œ
    """
    try:
        cutoff_date = datetime.strptime(delete_before_date, "%Y-%m-%d")
    except ValueError:
        print("é”™è¯¯: æ—¥æœŸæ ¼å¼ä¸æ­£ç¡®ï¼Œè¯·ä½¿ç”¨'YYYY-MM-DD'æ ¼å¼")
        return

    if not stock_files:
        print("æœªæ‰¾åˆ°ä»»ä½•stock_xxx.csvæ–‡ä»¶")
        return

    print(f"æ‰¾åˆ° {len(stock_files)} ä¸ªstockæ–‡ä»¶ï¼Œåˆ†å—å¤§å°: {chunk_size} è¡Œ")

    processed_files = 0
    deleted_files = 0
    cleaned_files = 0

    for file_path in stock_files:
        temp_file = None
        try:
            print(f"\næ­£åœ¨å¤„ç†æ–‡ä»¶: {file_path}")

            # é¦–å…ˆæ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºç©º
            file_size = os.path.getsize(file_path)
            if file_size == 0:
                print(f"æ–‡ä»¶ {file_path} ä¸ºç©ºï¼Œåˆ é™¤æ–‡ä»¶")
                os.remove(file_path)
                deleted_files += 1
                continue

            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
            temp_file = tempfile.NamedTemporaryFile(
                mode="w",
                newline="",
                encoding="utf-8",
                delete=False,
                suffix=".csv",
                dir=os.path.dirname(file_path),
            )
            temp_path = temp_file.name
            temp_file.close()  # å…³é—­æ–‡ä»¶ï¼Œpandasä¼šé‡æ–°æ‰“å¼€

            # ä½¿ç”¨pandasåˆ†å—è¯»å–å’Œå¤„ç†
            total_rows = 0
            kept_rows = 0
            first_chunk = True

            # åˆ†å—è¯»å–CSVæ–‡ä»¶
            chunk_iterator = pd.read_csv(file_path, chunksize=chunk_size)

            for i, chunk in enumerate(chunk_iterator):
                total_rows += len(chunk)

                # ç¡®ä¿dateåˆ—æ˜¯datetimeç±»å‹
                try:
                    chunk["date"] = pd.to_datetime(chunk["date"])
                except Exception as e:
                    print(f"è­¦å‘Š: åœ¨å¤„ç†å— {i + 1} æ—¶æ—¥æœŸè½¬æ¢å‡ºé”™: {str(e)}")
                    # å¦‚æœæ—¥æœŸè½¬æ¢å¤±è´¥ï¼Œä¿ç•™æ•´ä¸ªå—
                    chunk_clean = chunk
                else:
                    # ç­›é€‰å‡ºéœ€è¦ä¿ç•™çš„æ•°æ®ï¼ˆæ—¥æœŸä¸æ—©äºæŒ‡å®šæ—¥æœŸï¼‰
                    mask = chunk["date"] >= cutoff_date
                    chunk_clean = chunk[mask]

                kept_rows += len(chunk_clean)

                # å†™å…¥å¤„ç†åçš„æ•°æ®å—
                if first_chunk:
                    # ç¬¬ä¸€ä¸ªå—å†™å…¥è¡¨å¤´
                    chunk_clean.to_csv(temp_path, mode="w", index=False)
                    first_chunk = False
                else:
                    # åç»­å—è¿½åŠ ï¼Œä¸å†™å…¥è¡¨å¤´
                    chunk_clean.to_csv(temp_path, mode="a", header=False, index=False)

                print(f"  - å·²å¤„ç† {total_rows} è¡Œï¼Œä¿ç•™ {kept_rows} è¡Œ")

            # åˆ¤æ–­å¤„ç†ç»“æœ
            if kept_rows == 0:
                print(f"æ–‡ä»¶ {file_path}: æ‰€æœ‰ {total_rows} æ¡è®°å½•éƒ½è¢«åˆ é™¤ï¼Œåˆ é™¤æ–‡ä»¶")
                os.remove(file_path)
                if os.path.exists(temp_path):
                    os.remove(temp_path)
                deleted_files += 1
            elif kept_rows < total_rows:
                print(
                    f"æ–‡ä»¶ {file_path}: ä» {total_rows} æ¡è®°å½•æ¸…ç†åˆ° {kept_rows} æ¡è®°å½•"
                )
                # ç”¨ä¸´æ—¶æ–‡ä»¶æ›¿æ¢åŸæ–‡ä»¶
                os.replace(temp_path, file_path)
                cleaned_files += 1
            else:
                print(f"æ–‡ä»¶ {file_path}: æ‰€æœ‰ {total_rows} æ¡è®°å½•å‡æ— éœ€æ¸…ç†")
                # åˆ é™¤ä¸´æ—¶æ–‡ä»¶ï¼Œä¿ç•™åŸæ–‡ä»¶
                if os.path.exists(temp_path):
                    os.remove(temp_path)
                processed_files += 1

        except Exception as e:
            print(f"å¤„ç†æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {str(e)}")
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if temp_file and os.path.exists(temp_file.name):
                os.remove(temp_file.name)

    # è¾“å‡ºæ€»ç»“
    print("\nå¤„ç†å®Œæˆ!")
    print(f"å¤„ç†æ–‡ä»¶æ€»æ•°: {len(stock_files)}")
    print(f"å®Œå…¨åˆ é™¤çš„æ–‡ä»¶: {deleted_files}")
    print(f"éƒ¨åˆ†æ¸…ç†çš„æ–‡ä»¶: {cleaned_files}")
    print(f"æ— éœ€æ›´æ”¹çš„æ–‡ä»¶: {processed_files}")


def preview_clean_effect_pandas(
    stock_files, delete_before_date="2024-01-01", sample_size=5000
):
    """
    é¢„è§ˆæ¸…ç†æ•ˆæœï¼Œä½¿ç”¨pandasè¿›è¡Œé«˜æ•ˆæŠ½æ ·

    å‚æ•°:
    delete_before_date: åˆ é™¤æ—©äºæ­¤æ—¥æœŸçš„æ•°æ®
    sample_size: æŠ½æ ·å¤§å°ï¼Œé»˜è®¤5000è¡Œ
    """
    try:
        cutoff_date = datetime.strptime(delete_before_date, "%Y-%m-%d")
    except ValueError:
        print("é”™è¯¯: æ—¥æœŸæ ¼å¼ä¸æ­£ç¡®ï¼Œè¯·ä½¿ç”¨'YYYY-MM-DD'æ ¼å¼")
        return

    if not stock_files:
        print("æœªæ‰¾åˆ°ä»»ä½•stock_xxx.csvæ–‡ä»¶")
        return

    print(f"æ‰¾åˆ° {len(stock_files)} ä¸ªstockæ–‡ä»¶")
    print(f"é¢„è§ˆåˆ é™¤æ—©äº {delete_before_date} çš„æ•°æ®æ•ˆæœ:\n")

    for file_path in stock_files:
        try:
            # è·å–æ–‡ä»¶å¤§å°ä»¥ä¼°ç®—æ€»è¡Œæ•°
            file_size = os.path.getsize(file_path)
            if file_size == 0:
                print(f"ğŸ—‘ï¸ {file_path}: ç©ºæ–‡ä»¶ (å°†è¢«åˆ é™¤)")
                continue

            # ä½¿ç”¨pandasè¯»å–å‰å‡ è¡Œè¿›è¡Œé¢„è§ˆ
            df_sample = pd.read_csv(file_path, nrows=sample_size)

            if df_sample.empty:
                print(f"ğŸ—‘ï¸ {file_path}: æ— æ•°æ® (å°†è¢«åˆ é™¤)")
                continue

            # ç¡®ä¿dateåˆ—æ˜¯datetimeç±»å‹
            try:
                df_sample["date"] = pd.to_datetime(df_sample["date"])
            except Exception as e:
                print(f"âŒ {file_path}: æ—¥æœŸæ ¼å¼é”™è¯¯ - {str(e)}")
                continue

            # ç»Ÿè®¡ç¬¦åˆæ¡ä»¶çš„æ•°æ®
            mask = df_sample["date"] >= cutoff_date
            kept_count = mask.sum()
            total_count = len(df_sample)

            # ä¼°ç®—æ€»è¡Œæ•°
            if total_count > 0:
                estimated_total = int(
                    file_size / (os.path.getsize(file_path) / total_count)
                )
            else:
                estimated_total = 0

            if kept_count == 0:
                print(
                    f"ğŸ—‘ï¸ {file_path}: æ‰€æœ‰çº¦ {estimated_total} æ¡è®°å½•éƒ½å°†è¢«åˆ é™¤ (æ–‡ä»¶å°†è¢«åˆ é™¤)"
                )
            elif kept_count < total_count:
                deleted_count = total_count - kept_count
                # ä¼°ç®—æ€»åˆ é™¤æ•°
                estimated_deleted = int(deleted_count * (estimated_total / total_count))
                estimated_kept = estimated_total - estimated_deleted
                print(
                    f"ğŸ§¹ {file_path}: é¢„è®¡å°†åˆ é™¤çº¦ {estimated_deleted} æ¡è®°å½•ï¼Œä¿ç•™çº¦ {estimated_kept} æ¡è®°å½•"
                )
            else:
                print(f"âœ… {file_path}: æ‰€æœ‰çº¦ {estimated_total} æ¡è®°å½•å‡éœ€è¦ä¿ç•™")

        except Exception as e:
            print(f"âŒ {file_path}: è¯»å–é”™è¯¯ - {str(e)}")


def get_file_stats(stock_files):
    """
    è·å–æ‰€æœ‰stockæ–‡ä»¶çš„ç»Ÿè®¡ä¿¡æ¯
    """
    if not stock_files:
        print("æœªæ‰¾åˆ°ä»»ä½•stock_xxx.csvæ–‡ä»¶")
        return

    print(f"æ‰¾åˆ° {len(stock_files)} ä¸ªstockæ–‡ä»¶")
    print("\næ–‡ä»¶ç»Ÿè®¡ä¿¡æ¯:")
    print("-" * 60)

    total_size = 0
    total_rows = 0

    for file_path in stock_files:
        try:
            file_size = os.path.getsize(file_path)
            total_size += file_size

            # ä½¿ç”¨pandasè¯»å–æ–‡ä»¶è·å–è¡Œæ•°
            df = pd.read_csv(file_path, nrows=1)  # åªè¯»å–ä¸€è¡Œæ¥æ£€æŸ¥ç»“æ„
            row_count = sum(1 for line in open(file_path)) - 1  # å‡å»è¡¨å¤´

            total_rows += row_count

            print(
                f"{os.path.basename(file_path):<20} | å¤§å°: {file_size / 1024 / 1024:.2f} MB | è¡Œæ•°: {row_count:>8}"
            )

        except Exception as e:
            print(f"{os.path.basename(file_path):<20} | è¯»å–é”™è¯¯: {str(e)}")

    print("-" * 60)
    print(
        f"{'æ€»è®¡':<20} | å¤§å°: {total_size / 1024 / 1024:.2f} MB | è¡Œæ•°: {total_rows:>8}"
    )


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="æ¸…ç†è‚¡ç¥¨æ•°æ®æ–‡ä»¶")
    parser.add_argument(
        "--date",
        type=str,
        default="2024-01-01",
        help="åˆ é™¤æ—©äºæ­¤æ—¥æœŸçš„æ•°æ®ï¼Œæ ¼å¼: YYYY-MM-DD",
    )
    parser.add_argument(
        "--chunk-size", type=int, default=10000, help="åˆ†å—å¤„ç†çš„å¤§å°ï¼Œé»˜è®¤10000è¡Œ"
    )
    parser.add_argument(
        "--preview", action="store_true", help="ä»…é¢„è§ˆæ¸…ç†æ•ˆæœï¼Œä¸æ‰§è¡Œå®é™…æ¸…ç†"
    )
    parser.add_argument("--stats", action="store_true", help="æ˜¾ç¤ºæ–‡ä»¶ç»Ÿè®¡ä¿¡æ¯")

    args = parser.parse_args()
    file_pattern = "stock_*.csv"
    data_dir = "./usstockinfo"
    stock_files = glob.glob(os.path.join(data_dir, file_pattern))

    # æ˜¾ç¤ºæ–‡ä»¶ç»Ÿè®¡ä¿¡æ¯
    if args.stats:
        get_file_stats(stock_files)
        exit(0)

    # é¢„è§ˆæ¸…ç†æ•ˆæœ
    if args.preview:
        print("=== é¢„è§ˆæ¸…ç†æ•ˆæœ ===")
        preview_clean_effect_pandas(stock_files, args.date)
        exit(0)

    # æ‰§è¡Œå®é™…æ¸…ç†
    print("=== æ‰§è¡Œå®é™…æ¸…ç† ===")
    print(f"å°†åˆ é™¤æ—©äº {args.date} çš„æ•°æ®")
    print(f"åˆ†å—å¤§å°: {args.chunk_size} è¡Œ")

    user_input = input("ç¡®è®¤æ‰§è¡Œæ¸…ç†æ“ä½œ? (y/N): ")
    if user_input.lower() == "y":
        clean_stock_data_pandas_batch(stock_files, args.date, args.chunk_size)
    else:
        print("å–æ¶ˆæ¸…ç†æ“ä½œ")
